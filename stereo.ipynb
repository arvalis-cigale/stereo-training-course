{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef1d4283-b13c-4299-8774-4dbdcea454f0",
   "metadata": {},
   "source": [
    "https://docs.opencv.org/4.x/d9/db7/tutorial_py_table_of_contents_calib3d.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085a299b-121b-4727-aada-618372bcdb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import open3d as o3d\n",
    "import laspy\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from IPython import display\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "import stereolib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d355c1f2-43ac-4f35-bdf5-ad4225550b30",
   "metadata": {},
   "source": [
    "@article{Zhou2018,\n",
    "    author    = {Qian-Yi Zhou and Jaesik Park and Vladlen Koltun},\n",
    "    title     = {{Open3D}: {A} Modern Library for {3D} Data Processing},\n",
    "    journal   = {arXiv:1801.09847},\n",
    "    year      = {2018},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3364f9d-4b6c-4ea2-a9df-14b53924362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the data directory\n",
    "path_data = Path(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30359671-95cb-439d-a74a-2c2be26a7632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load calibration matrices and vectors\n",
    "calibration_path = path_data / Path(\"calibration\") / Path(\"literal_v2\")\n",
    "\n",
    "# Calibration path for Literal v2    \n",
    "calibration_filename = calibration_path / \"Tricam.yaml\"\n",
    "\n",
    "# If this file exists, then load calibration from its content\n",
    "if os.path.exists(calibration_filename):\n",
    "\n",
    "    img_size_left, camera_mtx_left, dist_coefs_left, \\\n",
    "    img_size_right, camera_mtx_right, dist_coefs_right, \\\n",
    "    R_pair, T_pair, \\\n",
    "    serial_number, \\\n",
    "    calibration_datetime = stereolib.load_calibration_from_yaml(calibration_filename)\n",
    "\n",
    "# Calibration has to be loaded from files previously generated with calibration.ipynb, from chessboard images\n",
    "else:\n",
    "    \n",
    "    img_size_left, camera_mtx_left, dist_coefs_left, \\\n",
    "    img_size_right, camera_mtx_right, dist_coefs_right, \\\n",
    "    R_pair, T_pair = stereolib.load_calibration_from_numpy(calibration_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220405f9-292c-4d34-8496-22b63084239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the transformation matrices for rectification, from the intrinsic and distorsion parameters of each camera, \n",
    "# and rotation and translation matrices describing related positions of left and right cameras (coming from stereo calibration)\n",
    "R_rect_left, R_rect_right, \\\n",
    "P_rect_left, P_rect_right, \\\n",
    "Q_rect_left, \\\n",
    "valid_pix_roi_1, valid_pix_roi_2  = cv.stereoRectify(camera_mtx_left,\n",
    "                                                     dist_coefs_left,\n",
    "                                                     camera_mtx_right,\n",
    "                                                     dist_coefs_right,\n",
    "                                                     img_size_left,\n",
    "                                                     R_pair,\n",
    "                                                     T_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4182a39c-8ea6-4c12-9b94-7c8976a2ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the maps (offset along rows and columns) to be applied to each pixel of each camera image (left and right), so that the left and right images\n",
    "# are rectified (= lines of the two cameras are aligned)\n",
    "# Left camera\n",
    "map_left_1, map_left_2 = cv.initUndistortRectifyMap(camera_mtx_left,\n",
    "                                                    dist_coefs_left,\n",
    "                                                    R_rect_left,\n",
    "                                                    P_rect_left,\n",
    "                                                    img_size_left,\n",
    "                                                    cv.CV_16SC2)\n",
    "\n",
    "# Right camera\n",
    "map_right_1, map_right_2 = cv.initUndistortRectifyMap(camera_mtx_right,\n",
    "                                                      dist_coefs_right,\n",
    "                                                      R_rect_right,\n",
    "                                                      P_rect_right,\n",
    "                                                      img_size_right,\n",
    "                                                      cv.CV_16SC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1bd17f-09f4-44b5-80ec-4bc08483f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance between the two cameras, in mm. Expressed in mm, because at the calibration step, we specified the chessboard cell size in millimeters.\n",
    "# This is simply computed considering the norm of the translation vector resulting of the stereo calibration pair.\n",
    "baseline = np.linalg.norm(T_pair)\n",
    "\n",
    "print(f\"baseline = {baseline} mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c5c1e-b737-47dc-8797-1323e9086e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal length obtained after rectification, expressed in pixels \n",
    "focal_length = P_rect_left[0][0]\n",
    "\n",
    "print(f\"focal length = {focal_length} pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe68db65-01f6-47cc-b74e-fbfef7868869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for Literal v2 images\n",
    "path_rgb_images = path_data / Path(\"inputs\")\n",
    "\n",
    "# Elements composing the name of our images\n",
    "name_base_camera = \"Tricam1Camera\"\n",
    "left_id = 1\n",
    "right_id = 2\n",
    "plot_id = \"556-A\"\n",
    "image_id = \"1\"\n",
    "image_ext = \"png\"\n",
    "\n",
    "# Name of the pair of images used\n",
    "name_img_left = path_rgb_images / f\"Plot{plot_id}_{name_base_camera}{left_id}_{image_id}.{image_ext}\"\n",
    "name_img_right = path_rgb_images / f\"Plot{plot_id}_{name_base_camera}{right_id}_{image_id}.{image_ext}\"\n",
    "\n",
    "# Load left and right input images\n",
    "img_left = stereolib.read_image(name_img_left)\n",
    "img_right = stereolib.read_image(name_img_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a28727-f0b5-47eb-8a28-7d26236de6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for generated outputs\n",
    "output_path = path_data / Path(\"outputs\")\n",
    "if os.path.isdir(output_path) is False:\n",
    "            os.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5a8262-1314-42bd-9112-916afda7c516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display input images\n",
    "stereolib.display_images([name_img_left, name_img_right])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f3dccb-9b1d-449c-baab-ed1fc47b0f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_left.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008839ed-5a1e-4426-a4d6-a1fce12b24a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rectify both images, so that the lines of the left image are matching those in the right image.\n",
    "rect_img_left = stereolib.rectify(img_left, map_left_1, map_left_2)\n",
    "rect_img_right = stereolib.rectify(img_right, map_right_1, map_right_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412cac4b-353c-4263-b32d-815d383ad2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save those images\n",
    "name_rect_img_left = output_path / \"rect_left_image.png\"\n",
    "name_rect_img_right = output_path / \"rect_right_image.png\"\n",
    "\n",
    "stereolib.write_image(name_rect_img_left, rect_img_left)\n",
    "stereolib.write_image(name_rect_img_right, rect_img_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a3567f-998f-46a8-a4fd-a5c14b59d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display rectified images\n",
    "stereolib.display_images([name_rect_img_left, name_rect_img_right])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702a83fb-dc0f-4b78-ad48-f3d724ebbcf1",
   "metadata": {},
   "source": [
    "In the rectification operation, we chose to keep the original image size : you can observe that both left image and right images were slightly tilted, black pixels added at the bottom of the left, and at the top and left of the right image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec53cf0-3d59-46b9-8066-91767dd2cd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the size of the recified image\n",
    "print(rect_img_left.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5ef7d6-2242-45c3-af3a-7498600d1da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store height and width for further use\n",
    "height, width = rect_img_left.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41033a25-61a1-46a2-9241-c8a2688f975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of depth_image in which something is interesting (depending on one's application), in mm\n",
    "range_operating_depth = [1200, 2800]\n",
    "\n",
    "# Compute disparities corresponding to the given range\n",
    "min_disparity_init = int(stereolib.compute_disparity_from_depth(baseline, focal_length, range_operating_depth[1]))\n",
    "\n",
    "# Prohibits the '0' value (would lead to infinite depth_image as Z = (baseline * focal_length) / disparity)\n",
    "min_disparity_init = max(min_disparity_init, 1)\n",
    "min_disparity_init = int(min_disparity_init)\n",
    "print(f\"Min disparity boundary : {min_disparity_init}\")\n",
    "\n",
    "# Rounds to upper digit to ensure to matching the desired value\n",
    "max_disparity_init = int(stereolib.compute_disparity_from_depth(baseline, focal_length, range_operating_depth[0])) + 1\n",
    "print(f\"Max disparity boundary : {max_disparity_init}\")\n",
    "\n",
    "# Compute the number of disparities (must be a multiple of 16)\n",
    "num_disparities_init = stereolib.compute_number_of_disparities(min_disparity_init, max_disparity_init)\n",
    "print(f\"Number of disparities : {num_disparities_init}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ee0f4f-0017-4c1d-a918-abb9fcd4b49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert RGB images to grayscale for matching (not mandatory, may work with RGB images, but more demanding in terms of computation power and of quality of the input images)\n",
    "rect_gray_img_left = cv.cvtColor(rect_img_left, cv.COLOR_BGR2GRAY)\n",
    "rect_gray_img_right = cv.cvtColor(rect_img_right, cv.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2b2d88-e255-4180-969d-b29248428ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As images are rectified and both lines aligned, you may choose to downsample images along lines to reduce processing time and CPU charge\n",
    "# (dependending on the resolution and objects size)\n",
    "# Here for example we downsample by a 4 factor\n",
    "factor_dwns = 4\n",
    "rect_gray_img_left_dwns = np.copy(rect_gray_img_left[::factor_dwns, ...])\n",
    "rect_gray_img_right_dwns = np.copy(rect_gray_img_right[::factor_dwns, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb1da71-7193-421f-8432-02ebfe0af698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for filtering the disparity (/!\\ : good rendering but may lead to approximations in distances). We don't activate filtering by default.\n",
    "wls_activation = False\n",
    "wls_sigma = 1.2\n",
    "\n",
    "# Compute the disparity using for SGBM algorithm, with efficient parameters (for our application and from our experience)\n",
    "ret, disparity_map, min_disparity, max_disparity = stereolib.stereo_processing(rect_gray_img_left_dwns,\n",
    "                                                                               rect_gray_img_right_dwns,\n",
    "                                                                               Q_rect_left,\n",
    "                                                                               min_disparity_init,\n",
    "                                                                               num_disparities_init,\n",
    "                                                                               block_size=3,\n",
    "                                                                               uniqueness_ratio=1,\n",
    "                                                                               wls_activation=False,\n",
    "                                                                               wls_sigma=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa49223-47cb-44be-84a3-609814dd33f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "disparity_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9b055a-4081-456f-9375-5477121d9f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "disparity_map.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b724f5b6-d297-4b75-9bd7-3ef0ed133b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9fb379-5ac0-40f9-a219-3eddf0416388",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(disparity_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f4e878-8cc6-429c-a973-cbec2848346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(disparity_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f5b8d4-f00a-4af8-9654-c1ba378b56f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the normalized total gradient to evaluate the matching quality : the principle is to compare and the left and the right-on-left mapped image obtained by applying disparity\n",
    "# to each pixel.\n",
    "# The ntg value is normalized in the [0, 1] interval ; a lower value means a good matching (generally around 0.2 / 0.3) and a higher one (above 0.5) a bad disparty map quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e407a6-33d4-4347-b152-2e3afe74dc4c",
   "metadata": {},
   "source": [
    "@article{\n",
    "    author    = {Chen, Shu-Jie & Shen, Hui-Liang & Li, Chunguang & Xin, John.},\n",
    "    title     = {Normalized Total Gradient: A New Measure for Multispectral Image Registration.},\n",
    "    journal   = {IEEE Transactions on Image Processing. PP. 1-1. 10.1109/TIP.2017.2776753.},\n",
    "    year      = {2017},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d514121-b0b3-409a-ab8e-d609da8dd1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntg_value, difference_img, right_on_left = stereolib.normalized_total_gradient(rect_gray_img_left_dwns,\n",
    "                                                                               disparity_map,\n",
    "                                                                               rect_gray_img_right_dwns,\n",
    "                                                                               min_disparity=min_disparity,\n",
    "                                                                               max_disparity=max_disparity,\n",
    "                                                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41cd8d5-037f-4001-9ded-9faf9874d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntg_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f9b3e7-a71a-4357-b2ca-5081f3a75bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect_gray_img_left_dwns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e51392a-e6f1-40ae-bd58-bee9a93ab434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As (if) downsampling has been done, we have to resize and interpolate disparity map to original RGB images size\n",
    "disparity_map = cv.resize(disparity_map, (width, height), cv.INTER_LINEAR_EXACT)\n",
    "difference_img = cv.resize(difference_img, (width-max_disparity, height), cv.INTER_LINEAR_EXACT)\n",
    "right_on_left = cv.resize(right_on_left, (width-max_disparity, height), cv.INTER_LINEAR_EXACT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122bbbd4-e756-4ddb-b989-53e24831679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save those images\n",
    "name_left_img = output_path / \"ntg_left_image.png\"\n",
    "name_difference_img = output_path / \"ntg_difference_image.png\"\n",
    "name_right_on_left_img = output_path / \"ntg_right_on_left_image.png\"\n",
    "\n",
    "stereolib.write_image(name_left_img, rect_gray_img_left[:, max_disparity:])\n",
    "stereolib.write_image(name_difference_img, difference_img)\n",
    "stereolib.write_image(name_right_on_left_img, right_on_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7f8f18-595c-4453-9ccd-6c84edc17417",
   "metadata": {},
   "outputs": [],
   "source": [
    "stereolib.display_images([name_left_img, name_right_on_left_img, name_difference_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378f2311-989e-4df0-a16d-bd124aff7310",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect_gray_img_left[:, max_disparity:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0179748-5f0a-4016-9f28-42c9a632671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa56dd6-7129-4c23-8775-e0a57dca3254",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_on_left.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ffa0ea-f2fd-44a5-b003-40b3004503bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_on_left[:, max_disparity:].shape\n",
    "\n",
    "name_right_on_left_img = output_path / \"ntg_right_on_left_image_short.png\"\n",
    "\n",
    "stereolib.write_image(name_right_on_left_img, right_on_left[:, min_disparity:])\n",
    "\n",
    "stereolib.display_images([name_right_on_left_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3595b76-3692-492b-9fab-2872753bb920",
   "metadata": {},
   "outputs": [],
   "source": [
    "disparity_image = stereolib.normalize_image(disparity_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e050940c-52c9-4585-bdd4-8e52132039cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(disparity_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da37d73b-40ea-49ed-8a7b-b93358abc59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(disparity_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45310636-52fb-44c6-8982-c2398c149e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "disparity_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db66a08f-f48a-4aa8-b0bd-55b33d2936fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "disparity_image.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95daf943-b83d-41a8-bee3-0ae6d0b5e258",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_disparity_image = output_path / \"disparity.png\"\n",
    "\n",
    "stereolib.write_image(name_disparity_image, disparity_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8299b6c1-9c66-4ef6-b23e-63cb4ac3388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stereolib.display_images([name_disparity_image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b223f6-8f57-4610-b8a5-46e4b95ad427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixels for which no correspondence has been found are set to 'min_disparity-1' by the SGBM algorithm.\n",
    "# We set these pixels to a negative value for easier discrimination (corresponding distances will be <0 too)\n",
    "\n",
    "disparity_map[disparity_map == min_disparity - 1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341f203c-a33a-4eb2-b018-45910baf1328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 channels image containing (X, Y, Z) coordinates in mm of each pixel (in the rectified left reference frame)\n",
    "xyz_image = cv.reprojectImageTo3D(disparity_map, Q_rect_left, handleMissingValues=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c31ffb-b4c3-4432-9718-c8d2e1c0c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the left stripe corresponding to max disparity (closest pixels not seen in the right image) in the 3 images that need to be coregistered\n",
    "# Here you could choose not to work on the full image, but on a central cropped zone for example, or on a masked region (if you have a vegetation\n",
    "# segmentation mask generated from the RGB left image for example ; in this case, be careful to correctly rectify your mask as was done with the\n",
    "# left RGB image, so that it's correctly coregistered with your left RGB image)\n",
    "rect_img_left = rect_img_left[:, max_disparity:]\n",
    "disparity_map = disparity_map[:, max_disparity:]\n",
    "xyz_image = xyz_image[:, max_disparity:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f560ce-7c25-4218-8a9e-1f78077bd246",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_image = xyz_image[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b4e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5bfe21-f4cd-46ae-b340-a56b002db03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We choose a step of 1 cm, which seems a be a correct compromise considering the acquisition system and context.\n",
    "hist_range = int((np.max(depth_image) - np.min(depth_image)) / 10.)\n",
    "\n",
    "# Compute the full depth_array histogram, without any filtering\n",
    "depth_hist, depth_bins = np.histogram(depth_image, bins=hist_range)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.plot(depth_bins[1:], depth_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe3d944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the depth_image histogram, without the Z negative erratic values (corresponding to pixels \n",
    "# for which no correspondence was found between left and right images)\n",
    "depth_array = xyz_image[:,:,2][xyz_image[:,:,2] >= 0]\n",
    "\n",
    "# We choose a step of 1 cm, which seems a be a correct compromise considering the acquisition system and context.\n",
    "hist_range = int((np.max(depth_array) - np.min(depth_array)) / 10.)\n",
    "\n",
    "depth_hist, depth_bins = np.histogram(depth_array, bins=hist_range)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.plot(depth_bins[1:], depth_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4f1557-8cd0-4682-87d1-5d3d3bcbcc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove erratic reamining points, that may lead to bad soil distance estimation or plant height estimation, we will work with the 3D point cloud\n",
    "# for an optimal filtering efficiency\n",
    "\n",
    "# Copy the original (X,Y,Z) point cloud before downsampling\n",
    "xyz_dwn_filtered = (np.copy(xyz_image).reshape(-1, 3).astype(np.float64))\n",
    "\n",
    "# Keep only the valid Z values, i.e. positive ones (negative values dued to invalid disparity set to -1\n",
    "valid_z_values, = np.where(xyz_dwn_filtered[:, 2] >= 0)\n",
    "\n",
    "# Copy the original (R,G,B) point cloud before downsampling\n",
    "rgb_left_dwn_filtered = (np.copy(rect_img_left).reshape(-1, 3).astype(np.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a375ed-6efb-49bd-9e51-0b394945b657",
   "metadata": {},
   "source": [
    "If open3d package doesn't work, skip the following cells until you find @no_open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9e7dd2-88f4-4cc9-a10d-231d370dba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 channels (X,Y,Z) image into a Open3D point cloud \n",
    "pcd_xyz = o3d.geometry.PointCloud()\n",
    "pcd_xyz.points = o3d.utility.Vector3dVector(xyz_dwn_filtered[valid_z_values])\n",
    "\n",
    "# Convert 3 channels (R,G,B) image into a Open3D point cloud \n",
    "pcd_rgb = o3d.geometry.PointCloud()\n",
    "pcd_rgb.points = o3d.utility.Vector3dVector(rgb_left_dwn_filtered[valid_z_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7215be-3e7c-401c-93df-63a4d514102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(pcd_xyz.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7786fcbc-cb31-4848-8aaa-c1922e0f6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling factor for \n",
    "ptcld_downsampling_factor = 12\n",
    "\n",
    "# Downsample original (X,Y,Z) point cloud for computation gain\n",
    "pcd_xyz_dwn = pcd_xyz.uniform_down_sample(every_k_points=ptcld_downsampling_factor)\n",
    "\n",
    "# Downsample corresponding (R,G,B) point cloud the same way\n",
    "pcd_rgb_dwn = pcd_rgb.uniform_down_sample(every_k_points=ptcld_downsampling_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1101f9e7-6eec-4c8f-ab28-431ae79405c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the (X,Y,Z) point cloud and corresponding (R,G,B) point cloud into classical numpy arrays for filtering\n",
    "xyz_dwn_filtered = np.array(pcd_xyz_dwn.points)\n",
    "rgb_left_dwn_filtered = np.array(pcd_rgb_dwn.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed8988e-92c0-429b-a677-76fc2399b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(xyz_dwn_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad50858-7884-4ecb-bca9-99d7c0290122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nb of neighbours for filtering\n",
    "nb_of_neighbors = 256\n",
    "# Standard deviation for filtering\n",
    "std_ratio = 0.05\n",
    "\n",
    "# Filter X,Y,Z point cloud ; returns the filtered X,Y,Z point cloud and the vector containing the indices of remaining valid points \n",
    "# in the original point cloud\n",
    "pcd_filtered, valid_pixels_array = pcd_xyz_dwn.remove_statistical_outlier(nb_neighbors=nb_of_neighbors, std_ratio=std_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df70a1a-06fd-4b8b-865f-ebfff42b6f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the valid points in the (X,Y,Z) and corresponding (R,G,B) point cloud\n",
    "xyz_dwn_filtered = xyz_dwn_filtered[valid_pixels_array]\n",
    "rgb_left_dwn_filtered = rgb_left_dwn_filtered[valid_pixels_array]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a887079-c623-40fc-85df-0161d0fdf984",
   "metadata": {},
   "source": [
    "@no_open3d : If open3d doesn't work go on executing from the cell below.\n",
    "Otherwise, skip the cell below and go to the next one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b03c6de-0db6-4097-b58c-14bcbe31a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the valid points in the (X,Y,Z) and corresponding (R,G,B) point cloud\n",
    "xyz_dwn_filtered = xyz_dwn_filtered[valid_z_values]\n",
    "rgb_left_dwn_filtered = rgb_left_dwn_filtered[valid_z_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02ca5e2-2507-4ed7-b486-0e3e6ce72cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the point cloud to be written\n",
    "point_cloud_name = output_path / \"pointcloud.laz\"\n",
    "\n",
    "# xyz_dwn_filtered = xyz_dwn_filtered[veg_mask_dwn_filtered>0]\n",
    "# rgb_left_dwn_filtered = rgb_left_dwn_filtered[veg_mask_dwn_filtered>0]\n",
    "stereolib.write_point_cloud(point_cloud_name, xyz_dwn_filtered, rgb_left_dwn_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0415fb-62b6-4ea8-9751-fcee01675742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the third channel of the (X,Y,Z) filtered downsampled array (float32 values, in mm), corresponding to z values, i.e. depth_image to sensor\n",
    "depth_array = xyz_dwn_filtered[:, 2]\n",
    "\n",
    "# Convert the floating values into rounded integer values (mm precision is more than what is reasonably achievable).\n",
    "depth_array = np.round(depth_array).astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb68fad2-e51a-4d25-903d-19bec6cf37ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the depth_array histogram\n",
    "\n",
    "# We choose a step of 1 cm, which seems a be a correct compromise considering the acquisition system and context.\n",
    "hist_range = int((np.max(depth_array) - np.min(depth_array)) / 10.)\n",
    "\n",
    "# Compute the depth_array histogram \n",
    "depth_hist, depth_bins = np.histogram(depth_array, bins=hist_range)\n",
    "#depth_hist, depth_bins = np.histogram(depth_array, bins=10)\n",
    "\n",
    "# We create a new figure\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Name of the horizontal axis\n",
    "ax.set_xlabel('Depth to sensor in mm')\n",
    "# Name of the vertical axis\n",
    "ax.set_ylabel('Normalized count of values')\n",
    "\n",
    "# Name of the plot\n",
    "ax.set_title(\"Depth distribution\")\n",
    "\n",
    "# Plot the histogram\n",
    "plt.plot(depth_bins[1:], depth_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a1f11e-4242-467d-ad3a-ca70e769561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth the histogram to remove micropeaks\n",
    "filtered_depth_hist = gaussian_filter1d(depth_hist, sigma=2)\n",
    "\n",
    "# We normalize the histogram\n",
    "norm_filtered_depth_hist = filtered_depth_hist / np.max(filtered_depth_hist)\n",
    "\n",
    "# We create a new figure\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Name of the horizontal axis\n",
    "ax.set_xlabel('Depth to sensor in mm')\n",
    "# Name of the vertical axis\n",
    "ax.set_ylabel('Normalized count of values')\n",
    "\n",
    "# Name of the plot\n",
    "ax.set_title(\"Depth distribution\")\n",
    "\n",
    "# We plot the filtered depth histogram\n",
    "plt.plot(depth_bins[1:], norm_filtered_depth_hist)\n",
    "#plt.savefig(output_path / Path('filtered_depth_hist.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63927d39-1dfc-409c-9c22-d2bec107b2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We look for peaks into the depth histogram. In the favourable case (such this one) where soil is not so masked by the vegetation, \n",
    "# we can assume that the last peak corresponds to the ground level.\n",
    "# The function returns peaks indices in the array, if any was found\n",
    "peaks, _ = find_peaks(norm_filtered_depth_hist, height=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603e67ea-032c-49e5-b01c-d7cefa410838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We display the depths corresponding to the peaks indices\n",
    "depth_bins[peaks+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763ae3f7-be4c-4ac8-a03d-33bac458b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assign the depth of the last peak to our ground estimated value\n",
    "ground_depth = 0\n",
    "if len(peaks) > 0:\n",
    "    ground_depth = depth_bins[peaks[-1]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5859e1d-da3d-4bc2-a0b6-68cff23d3c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_depth = np.round(ground_depth).astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b59653",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620180aa-b598-42e9-9cdd-e34eb7f228ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a new figure\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# We plot once again the filtered depth histogram\n",
    "plt.plot(depth_bins[1:], norm_filtered_depth_hist)\n",
    "\n",
    "# Margins and limits of the plot\n",
    "ax.margins(x=0, y=0)\n",
    "ax.set_ylim(0, 1.1)\n",
    "\n",
    "# We plot the vertical line corresponding to the ground estimated depth\n",
    "plt.vlines(ground_depth, 0,1, linestyles='dashed', color='r')\n",
    "\n",
    "# We annotate the line with appropriate value\n",
    "ax.annotate(f'{ground_depth}', xy=(ground_depth, 0), xytext=(2, 0),\n",
    "            textcoords='offset points',\n",
    "            ha='left', va='bottom',\n",
    "            fontsize=12, color='red')\n",
    "\n",
    "# Name of the horizontal axis\n",
    "ax.set_xlabel('Depth to sensor in mm')\n",
    "# Name of the vertical axis\n",
    "ax.set_ylabel('Normalized count of values')\n",
    "\n",
    "# Name of the plot\n",
    "ax.set_title(\"Depth distribution\")\n",
    "\n",
    "plt.savefig(output_path / Path('filtered_depth_hist.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8c0b8b-cf56-46e4-b2a5-8f434996cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heigths may then be simply estimated by calculating the difference between the ground distance and the distances to objects\n",
    "height_array = ground_depth - depth_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37414e1-8fbb-4c5a-bc3c-ec0148e3e829",
   "metadata": {},
   "outputs": [],
   "source": [
    "height_array = height_array[height_array > 0]\n",
    "height_array = height_array[height_array < ground_depth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd82650-85a4-4dd4-850c-d46f2bd8cfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We choose a step of 1 cm, which seems a be a correct compromise considering the acquisition system and context.\n",
    "hist_range = int((np.max(height_array) - np.min(height_array)) / 10.)\n",
    "\n",
    "# Compute the height histogram\n",
    "height_hist, height_bins = np.histogram(height_array, bins=hist_range)\n",
    "\n",
    "# Smooth the histogram to remove micropeaks, just as we did with depth\n",
    "filtered_height_hist = gaussian_filter1d(height_hist, sigma=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2ee52a-9cf2-40af-a89a-e614a70fce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a new figure\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Name of the horizontal axis\n",
    "ax.set_xlabel('Height above ground_depth in mm')\n",
    "# Name of the vertical axis\n",
    "ax.set_ylabel('Normalized count of values')\n",
    "\n",
    "# Name of the plot\n",
    "ax.set_title(\"Height distribution\")\n",
    "\n",
    "# We plot the histogram\n",
    "plt.plot(height_bins[1:], filtered_height_hist)\n",
    "plt.savefig(output_path / Path('filtered_height_hist.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d2ecd-b735-47e9-baf7-00771090cc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute the cumulative height distribution\n",
    "cumulative_height_distribution = np.cumsum(filtered_height_hist)\n",
    "\n",
    "# We normalize it so that valus are int the interval [0,1]\n",
    "cumulative_height_distribution = cumulative_height_distribution / np.max(cumulative_height_distribution)\n",
    "\n",
    "# We define the desired percentile of the distribution, that will lead to a consistent height value (for wheat), \n",
    "# based on many comparisons with manual height measurements.\n",
    "percentile = 0.98\n",
    "\n",
    "# We keep only height values that are above this percentile\n",
    "mean_height_array, = np.where(cumulative_height_distribution >= percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d847562-b027-447a-a6c2-80ecefe5713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_height_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4865e32-a196-4605-96fb-b2cb299d7ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We retrieve the first value and define it as the mean height\n",
    "mean_height = height_bins[mean_height_array[0]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293d8892-13db-4765-bd2d-b7a7b870e1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a new figure\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# We plot the cumulative heights histogram\n",
    "plt.plot(height_bins[1:], cumulative_height_distribution)\n",
    "\n",
    "# We plot the horizontal line corresponding to the desired percentile (98%) of the the height cumulative distribution count \n",
    "plt.hlines(0.98, 0, mean_height, linestyles='dashed', color='r')\n",
    "\n",
    "# We annotate the line with appropriate value\n",
    "ax.annotate(f'0.98', xy=(0, 0.98), xytext=(2, 0),\n",
    "            textcoords='offset points',\n",
    "            ha='left', va='bottom',\n",
    "            fontsize=12, color='red')\n",
    "\n",
    "# We plot the vertical line where the desired percentile (98%) is reached in the cumulative distribution\n",
    "plt.vlines(mean_height, 0, 0.98, linestyles='dashed', color='r')\n",
    "\n",
    "# We annotate the line with appropriate value\n",
    "ax.annotate(f'{mean_height:.1f}', xy=(mean_height, 0), xytext=(2, 0),\n",
    "            textcoords='offset points',\n",
    "            ha='left', va='bottom',\n",
    "            fontsize=12, color='red')\n",
    "\n",
    "# Margins and limits of the plot\n",
    "ax.margins(x=0, y=0)\n",
    "ax.set_ylim(0, 1.1)\n",
    "\n",
    "# Name of the horizontal axis\n",
    "ax.set_xlabel('Heights in mm')\n",
    "# Name of the vertical axis\n",
    "ax.set_ylabel('Normalized count of values')\n",
    "\n",
    "# Name of the plot\n",
    "ax.set_title(\"Cumulative heights distribution\")\n",
    "\n",
    "plt.savefig(output_path / Path('cumulative_height_distribution.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c53df79-2f28-457e-8a28-a1a4011715cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f10cbec-260a-45b5-aa07-ee7ba3ae19fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(height_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f02d327-d598-443e-a380-260549119bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(height_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65324c2f-1854-4972-99b1-a9ed62e5f24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can go back to the non-filtered depth image to have a representation of the heights of objects in the image, \n",
    "# Distances are in mm in depth_image ; we divide those values by 10, so that we get the heights with a cm precision in a 8 bits image\n",
    "# (values between 0 and 255 cm)\n",
    "height_image = ((ground_depth - depth_image) / 10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4110fa5b-61ec-47ef-b182-02e74539ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "height_image[height_image < 0] = 0\n",
    "height_image[height_image > 255] = 0 \n",
    "\n",
    "height_image = height_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7041057-d254-499b-9fe5-67eeb0c92780",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf050ff-dada-4a8e-a455-e31fa84e3aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "height_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b5f22-3520-48ca-932f-986e2bd7df52",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_height_image = output_path / \"height.png\"\n",
    "\n",
    "stereolib.write_image(name_height_image, height_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859cc6ee-7fed-47ca-9995-7a57b6f111b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stereolib.display_images([name_height_image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596c246d-cd7c-4662-b95e-795d04df29f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stereo-venv",
   "language": "python",
   "name": "stereo-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
